{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"E:\\Azadeh\\Data Science-Lighthouse\\Datasets\\mini-project-V\\train.csv\\train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 404290 entries, 0 to 404289\n",
      "Data columns (total 6 columns):\n",
      " #   Column        Non-Null Count   Dtype \n",
      "---  ------        --------------   ----- \n",
      " 0   id            404290 non-null  int64 \n",
      " 1   qid1          404290 non-null  int64 \n",
      " 2   qid2          404290 non-null  int64 \n",
      " 3   question1     404289 non-null  object\n",
      " 4   question2     404288 non-null  object\n",
      " 5   is_duplicate  404290 non-null  int64 \n",
      "dtypes: int64(4), object(2)\n",
      "memory usage: 18.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    255027\n",
       "1    149263\n",
       "Name: is_duplicate, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution of classes\n",
    "\n",
    "df.is_duplicate.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       1\n",
       "question2       2\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking null values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(how='any',axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='is_duplicate'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the distribution of classes\n",
    "\n",
    "df.groupby(\"is_duplicate\")['id'].count().plot.bar(color={\"red\", \"blue\"})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzing the data set\n",
    "\n",
    "for i in range(0,10):\n",
    "    print(df.question1[i])\n",
    "    print(df.question2[i])\n",
    "    print()\n",
    "    \n",
    "for i in range(20,30):\n",
    "    print(df.question1[i])\n",
    "    print(df.question2[i])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cleaning\n",
    "\n",
    "- Tokenization\n",
    "- Stopwords cleaning\n",
    "- Removing punctuation\n",
    "- Normalizing\n",
    "- Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKENS = {\n",
    "    'quoted': 'quoted_item',\n",
    "    'non-ascii': 'non_ascii_word',\n",
    "    'undefined': 'something'\n",
    "}\n",
    "\n",
    "def clean(text, stem_words=True):\n",
    "    import re\n",
    "    from string import punctuation\n",
    "    from nltk.stem import SnowballStemmer\n",
    "    from nltk.corpus import stopwords\n",
    "    \n",
    "    def pad_str(s):\n",
    "        return ' '+s+' '\n",
    "    \n",
    "    if pd.isnull(text):\n",
    "        return ''\n",
    "\n",
    "#    stops = set(stopwords.words(\"english\"))\n",
    "    # Clean the text, with the option to stem words.\n",
    "    \n",
    "    # Empty question\n",
    "    \n",
    "    if type(text) != str or text=='':\n",
    "        return ''\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(\"\\'s\", \" \", text) # we have cases like \"Sam is\" or \"Sam's\" (i.e. his) these two cases aren't separable, I choose to compromise are kill \"'s\" directly\n",
    "    text = re.sub(\" whats \", \" what is \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(\"can't\", \"can not\", text)\n",
    "    text = re.sub(\"n't\", \" not \", text)\n",
    "    text = re.sub(\"i'm\", \"i am\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\'re\", \" are \", text)\n",
    "    text = re.sub(\"\\'d\", \" would \", text)\n",
    "    text = re.sub(\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(\"e\\.g\\.\", \" eg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"b\\.g\\.\", \" bg \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(\\d+)(kK)\", \" \\g<1>000 \", text)\n",
    "    text = re.sub(\"e-mail\", \" email \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?U\\.S\\.A\\.\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"(the[\\s]+|The[\\s]+)?United State(s)?\", \" America \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"\\(s\\)\", \" \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\"[c-fC-F]\\:\\/\", \" disk \", text)\n",
    "    \n",
    "    # remove comma between numbers, i.e. 15,000 -> 15000\n",
    "    \n",
    "    text = re.sub('(?<=[0-9])\\,(?=[0-9])', \"\", text)\n",
    "    \n",
    "   \n",
    "    # add padding to punctuations and special chars, we still need them later\n",
    "    \n",
    "    text = re.sub('\\$', \" dollar \", text)\n",
    "    text = re.sub('\\%', \" percent \", text)\n",
    "    text = re.sub('\\&', \" and \", text)\n",
    "    \n",
    "      \n",
    "    text = re.sub('[^\\x00-\\x7F]+', pad_str(SPECIAL_TOKENS['non-ascii']), text) # replace non-ascii word with special word\n",
    "    \n",
    "    # indian dollar\n",
    "    \n",
    "    text = re.sub(\"(?<=[0-9])rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(\" rs(?=[0-9])\", \" rs \", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # clean text rules get from : https://www.kaggle.com/currie32/the-importance-of-cleaning-text\n",
    "    text = re.sub(r\" (the[\\s]+|The[\\s]+)?US(A)? \", \" America \", text)\n",
    "    text = re.sub(r\" UK \", \" England \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" india \", \" India \", text)\n",
    "    text = re.sub(r\" switzerland \", \" Switzerland \", text)\n",
    "    text = re.sub(r\" china \", \" China \", text)\n",
    "    text = re.sub(r\" chinese \", \" Chinese \", text) \n",
    "    text = re.sub(r\" imrovement \", \" improvement \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" intially \", \" initially \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" quora \", \" Quora \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dms \", \" direct messages \", text, flags=re.IGNORECASE)  \n",
    "    text = re.sub(r\" demonitization \", \" demonetization \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" actived \", \" active \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" kms \", \" kilometers \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" cs \", \" computer science \", text, flags=re.IGNORECASE) \n",
    "    text = re.sub(r\" upvote\", \" up vote\", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" iPhone \", \" phone \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" \\0rs \", \" rs \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" calender \", \" calendar \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" ios \", \" operating system \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gps \", \" GPS \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" gst \", \" GST \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" programing \", \" programming \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" bestfriend \", \" best friend \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" dna \", \" DNA \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" III \", \" 3 \", text)\n",
    "    text = re.sub(r\" banglore \", \" Banglore \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J K \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    text = re.sub(r\" J\\.K\\. \", \" JK \", text, flags=re.IGNORECASE)\n",
    "    \n",
    "    # replace the float numbers with a random number, it will be parsed as number afterward, and also been replaced with word \"number\"\n",
    "    \n",
    "    text = re.sub('[0-9]+\\.[0-9]+', \" 87 \", text)\n",
    "  \n",
    "    \n",
    "    # Remove punctuation from text\n",
    "    text = ''.join([c for c in text if c not in punctuation]).lower()\n",
    "       # Return a list of words\n",
    "    return text\n",
    "    \n",
    "df['question1'] = df['question1'].apply(clean)\n",
    "df['question2'] = df['question2'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "import unidecode\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove white spaces\n",
    "import re \n",
    "def remove_white_space(text):\n",
    "    sentence = re.sub(' +',' ', text)\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to remove puctuations\n",
    "def remove_punct(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove stopwords\n",
    "# Load the list of stopwords built into nltk\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "\n",
    "# Define a function to remove all stopwords\n",
    "def remove_stopwords(tokenized_text):    \n",
    "    text = [word for word in tokenized_text if word not in stopwords]\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stemming\n",
    "def stemmizer(tokenized_text):\n",
    "    \n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in tokenized_text]\n",
    "    return stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the data:\n",
    "def Normalize(data):\n",
    "    \n",
    "        data['question1']=  data['question1'].apply(lambda x: remove_white_space(x))\n",
    "        data['question2']=  data['question1'].apply(lambda x: remove_white_space(x))\n",
    "        \n",
    "        data['question1']=  data['question1'].apply(lambda x: unidecode.unidecode(x))\n",
    "        data['question2']=  data['question2'].apply(lambda x: unidecode.unidecode(x))\n",
    "        \n",
    "        data['question1']=  data['question1'].apply(lambda x: remove_punct(x))\n",
    "        data['question2']=  data['question2'].apply(lambda x: remove_punct(x))\n",
    "        \n",
    "        #data['question1']=  data['question1'].apply(lambda x: word_tokenize(x.lower()))\n",
    "        #data['question2']=  data['question2'].apply(lambda x: word_tokenize(x.lower()))\n",
    "        \n",
    "        #data['question1']=  data['question1'].apply(lambda x: remove_stopwords(x))\n",
    "        #data['question2']=  data['question2'].apply(lambda x: remove_stopwords(x))\n",
    "        \n",
    "        #data['question1']=  data['question1'].apply(lambda x: stemmizer(x))\n",
    "        #data['question2']=  data['question2'].apply(lambda x: stemmizer(x))\n",
    "        \n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_norm= Normalize(df) \n",
    "#df_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train['question1_clean']=  X_train['question1_clean'].apply(lambda x: stemmizer(x))\n",
    "#X_train['question1_clean']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.to_csv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "\n",
    "- tf-idf\n",
    "- Bag Of Words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "Different modeling techniques can be used:\n",
    "\n",
    "- logistic regression\n",
    "- XGBoost\n",
    "- Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.sparse import hstack\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TFIDF technique with XGboost and Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(analyzer='word', min_df = 2, stop_words = stopwords)\n",
    "\n",
    "tfidf.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
    "trainq1_trans = tfidf.transform(df['question1'].values)\n",
    "trainq2_trans = tfidf.transform(df['question2'].values)\n",
    "\n",
    "\n",
    "X = hstack((trainq1_trans,trainq2_trans))\n",
    "y = df['is_duplicate'].values\n",
    "\n",
    "X_train, X_test ,y_train, y_test = train_test_split(X,y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective ='binary:logistic', max_depth=50, n_estimators=80, learning_rate=0.1,use_label_encoder=False,eval_metric='logloss').fit(X_train, y_train) \n",
    "\n",
    "xgb_prediction = xgb_model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabulary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>zynga</th>\n",
       "      <td>50217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyrtec</th>\n",
       "      <td>50218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zyzz</th>\n",
       "      <td>50219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zz</th>\n",
       "      <td>50220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>zzzquil</th>\n",
       "      <td>50221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vocabulary\n",
       "zynga         50217\n",
       "zyrtec        50218\n",
       "zyzz          50219\n",
       "zz            50220\n",
       "zzzquil       50221"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#d = tfidf.vocabulary_\n",
    "df_tfidf= pd.DataFrame({'vocabulary': tfidf.vocabulary_})\n",
    "#tfidf.get_feature_names_out()\n",
    "df_tfidf.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf-idf training score: 0.8147011558699784\n",
      "tf-idf test score: 0.7281241882941261\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84     51026\n",
      "           1       0.82      0.50      0.62     29832\n",
      "\n",
      "    accuracy                           0.77     80858\n",
      "   macro avg       0.79      0.72      0.73     80858\n",
      "weighted avg       0.78      0.77      0.76     80858\n",
      "\n",
      "\n",
      "Accuracy on training set for XGBoost(n=80,depth=50): 0.382\n"
     ]
    }
   ],
   "source": [
    "print('tf-idf training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
    "print('tf-idf test score:', f1_score(y_test, xgb_model.predict(X_test), average='macro'))\n",
    "print(classification_report(y_test, xgb_prediction))\n",
    "print()\n",
    "print(\"Accuracy on training set for XGBoost(n=80,depth=50): {:.3f}\".format(xg_reg.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **recall** means \"how many of this class you find over the whole number of element of this class\"\n",
    "\n",
    "The **precision** will be \"how many are correctly classified among that class\"\n",
    "\n",
    "The **f1-score** is the harmonic mean between precision & recall\n",
    "\n",
    "The **support** is the number of occurence of the given class in your dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB #because binary \n",
    "\n",
    "NB= BernoulliNB()\n",
    "\n",
    "model = NB.fit(X_train, y_train)\n",
    "train_accuracy = model.score(X_train,y_train)\n",
    "test_accuracy = model.score(X_test,y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:\t0.7575696675313592\n",
      "Test accuracy:\t0.7283385688490934\n"
     ]
    }
   ],
   "source": [
    "#print(classification_report(y_test,lg_prediction))\n",
    "print(f'Train accuracy:\\t{train_accuracy}')\n",
    "print(f'Test accuracy:\\t{test_accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bag of words with XGBoost and Naive Bayes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training score: 0.8147011558699784\n",
      "validation score: 0.7281241882941261\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.93      0.84     51026\n",
      "           1       0.82      0.50      0.62     29832\n",
      "\n",
      "    accuracy                           0.77     80858\n",
      "   macro avg       0.79      0.72      0.73     80858\n",
      "weighted avg       0.78      0.77      0.76     80858\n",
      "\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "count_vect.fit(pd.concat((df['question1'],df['question2'])).unique())\n",
    "train1_trans = count_vect.transform(df['question1'].values)\n",
    "train2_trans = count_vect.transform(df['question2'].values)\n",
    "\n",
    "X = hstack((trainq1_trans,trainq2_trans))\n",
    "y = df['is_duplicate'].values\n",
    "\n",
    "X_train,X_test ,y_train,y_test = train_test_split(X,y, test_size = 0.20, random_state = 42)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective ='binary:logistic', max_depth=50, n_estimators=80, learning_rate=0.1,use_label_encoder=False,eval_metric='logloss').fit(X_train, y_train)  \n",
    "xgb_prediction = xgb_model.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import f1_score, classification_report, accuracy_score\n",
    "\n",
    "print('training score:', f1_score(y_train, xgb_model.predict(X_train), average='macro'))\n",
    "print('validation score:', f1_score(y_test, xgb_model.predict(X_test), average='macro'))\n",
    "print()\n",
    "print(classification_report(y_test, xgb_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>vocabulary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>000</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0000000</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         vocabulary\n",
       "0                 0\n",
       "00                1\n",
       "000               2\n",
       "0000              3\n",
       "0000000           4"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_countVec= pd.DataFrame({'vocabulary': count_vect.vocabulary_})\n",
    "#tfidf.get_feature_names_out()\n",
    "df_countVec.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NB.fit(X_train, y_train)\n",
    "train_accuracy = model.score(X_train,y_train)\n",
    "test_accuracy = model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy:\t0.7575696675313592\n",
      "Test accuracy:\t0.7283385688490934\n"
     ]
    }
   ],
   "source": [
    "print(f'Train accuracy:\\t{train_accuracy}')\n",
    "print(f'Test accuracy:\\t{test_accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "# Load Google's pre-trained Word2Vec model.\n",
    "model = gensim.models.KeyedVectors.load_word2vec_format(r\"E:\\Azadeh\\Data Science-Lighthouse\\Datasets\\GoogleNews-vectors-negative300.bin\\GoogleNews-vectors-negative300.bin\", binary=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
